config:
  llms:
    answer:
      provider: groq
      model: llama-3.3-70b-versatile
      base_url: https://api.groq.com/openai/v1/models
      stop:
        - <|start_header_id|>
        - <|end_header_id|>
        - <|eot_id|>
      temperature: 0.15
